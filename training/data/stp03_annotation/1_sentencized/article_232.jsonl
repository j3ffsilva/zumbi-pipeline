{"text":"RFI"}
{"text":"Especialistas da ONU (Organização das Nações Unidas) fizeram um alerta, nesta quinta (26), sobre os algoritmos de inteligência artificial utilizados para reconhecimento facial e controles policiais."}
{"text":"Eles dizem que essas ferramentas podem reforçar discriminações raciais e que países devem estar alertas."}
{"text":"Segundo a especialista jamaicana Verene Shepherd, 'existe um grande risco de que [a inteligência artificial] reforce o preconceito e, assim, agrave ou possibilite práticas discriminatórias'."}
{"text":"Shepherd é membro do comitê da Organização das Nações Unidas para a eliminação da discriminação racial, composto por 18 especialistas."}
{"text":"Nesta quinta, o grupo publicou um relatório com recomendações às autoridades para combater esse problema."}
{"text":"O comitê está particularmente preocupado com os algoritmos usados entre as ferramentas policiais de 'prevenção' ou 'avaliação de riscos'."}
{"text":"Esses sistemas de vigilância, que supostamente ajudam na prevenção de crimes e foram implementados pela primeira vez nos Estados Unidos no começo dos anos 2000, são criticados porque reforçam os preconceitos sobre algumas comunidades."}
{"text":"O grupo também chamou a atenção para o motor de busca usado pelas redes sociais, que filtra o conteúdo e pode mostrar aos usuários publicidade preconceitusa."}
{"text":"Ciclo vicioso 'Os dados históricos sobre prisões em um bairro determinado [que alimentam a inteligência artificial] podem refletir muito bem as práticas policiais preconceituosas' e, consequentemente, reproduzi-las, destaca Shepherd."}
{"text":"'Essas informações aumentam o risco de um excesso de presença policial que poderia levar a realizar mais prisões e, desse modo, criar um ciclo vicioso', alerta."}
{"text":"'Dados incorretos provocam maus resultados.' Entre as recomendações, o comitê também expressa preocupação pelo uso cada vez mais generalizado do reconhecimento facial ou outras tecnologias de supervisão utilizadas em missões de segurança."}
{"text":"Novamente, em relação a isso, o discernimento da inteligência artificial está intimamente vinculado aos dados usados para 'educar' esses sistemas, explica a especialista jamaicana."}
{"text":"Estudos realizados demonstraram que esses dados têm dificuldades para reconhecer os rostos de pele escura ou de mulheres."}
{"text":"Um exemplo disso foi a prisão, neste ano, na cidade de Detroit, nos Estados Unidos, de um homem negro americano, Robert Williams, com base em 'conclusões' de um algoritmo mal desenvolvido, que o identificou como o suspeito de um roubo."}
{"text":"'Recebemos reclamações sobre esta forma de identificação errônea fruto dessas tecnologias, de quem as desenvolve ou dos exemplos utilizados por esses sistemas', indica Shepherd, que acrescenta: 'É uma preocupação real'."}
{"text":"O comitê pede aos países que regulamentem as empresas que trabalham neste setor para garantir que tais sistemas respeitem as leis internacionais sobre direitos humanos."}
{"text":"O relatório insiste na necessidade de transparência na concepção e na aplicação desses direitos para a população."}
{"text":"As recomendações do comitê não se limitam a essas novas tecnologias."}
{"text":"'O desenvolvimento de perfis raciais não começou com elas', lembra Shepherd."}
{"text":"Ela espera que 'a intensificação e internacionalização do movimento Black Lives Matter (...) e outras campanhas que denunciam a discriminação contra grupos vulneráveis ajudem [a destacar] a importância dessas recomendações'."}
