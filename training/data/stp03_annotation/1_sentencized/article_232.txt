RFI

Especialistas da ONU (Organização das Nações Unidas) fizeram um alerta, nesta quinta (26), sobre os algoritmos de inteligência artificial utilizados para reconhecimento facial e controles policiais.

Eles dizem que essas ferramentas podem reforçar discriminações raciais e que países devem estar alertas.

Segundo a especialista jamaicana Verene Shepherd, 'existe um grande risco de que [a inteligência artificial] reforce o preconceito e, assim, agrave ou possibilite práticas discriminatórias'. Shepherd é membro do comitê da Organização das Nações Unidas para a eliminação da discriminação racial, composto por 18 especialistas.

Nesta quinta, o grupo publicou um relatório com recomendações às autoridades para combater esse problema.

O comitê está particularmente preocupado com os algoritmos usados entre as ferramentas policiais de 'prevenção' ou 'avaliação de riscos'. Esses sistemas de vigilância, que supostamente ajudam na prevenção de crimes e foram implementados pela primeira vez nos Estados Unidos no começo dos anos 2000, são criticados porque reforçam os preconceitos sobre algumas comunidades.

O grupo também chamou a atenção para o motor de busca usado pelas redes sociais, que filtra o conteúdo e pode mostrar aos usuários publicidade preconceitusa.

Ciclo vicioso 'Os dados históricos sobre prisões em um bairro determinado [que alimentam a inteligência artificial] podem refletir muito bem as práticas policiais preconceituosas' e, consequentemente, reproduzi-las, destaca Shepherd 'Essas informações aumentam o risco de um excesso de presença policial que poderia levar a realizar mais prisões e, desse modo, criar um ciclo vicioso', alerta. 'Dados incorretos provocam maus resultados.'Entre as recomendações, o comitê também expressa preocupação pelo uso cada vez mais generalizado do reconhecimento facial ou outras tecnologias de supervisão utilizadas em missões de segurança.

Novamente, em relação a isso, o discernimento da inteligência artificial está intimamente vinculado aos dados usados para 'educar' esses sistemas, explica a especialista jamaicana.

Estudos realizados demonstraram que esses dados têm dificuldades para reconhecer os rostos de pele escura ou de mulheres.

Um exemplo disso foi a prisão, neste ano, na cidade de Detroit, nos Estados Unidos, de um homem negro americano, Robert Williams, com base em 'conclusões' de um algoritmo mal desenvolvido, que o identificou como o suspeito de um roubo 'Recebemos reclamações sobre esta forma de identificação errônea fruto dessas tecnologias, de quem as desenvolve ou dos exemplos utilizados por esses sistemas', indica Shepherd, que acrescenta: 'É uma preocupação real'. O comitê pede aos países que regulamentem as empresas que trabalham neste setor para garantir que tais sistemas respeitem as leis internacionais sobre direitos humanos.

O relatório insiste na necessidade de transparência na concepção e na aplicação desses direitos para a população.

As recomendações do comitê não se limitam a essas novas tecnologias 'O desenvolvimento de perfis raciais não começou com elas', lembra Shepherd.

Ela espera que 'a intensificação e internacionalização do movimento Black Lives Matter (...) e outras campanhas que denunciam a discriminação contra grupos vulneráveis ajudem [a destacar] a importância dessas recomendações'. 