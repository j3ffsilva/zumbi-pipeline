André Santana é jornalista, cofundador do Instituto Mídia Étnica e do portal Correio Nagô

O documentário Dilema das Redes, exibido na Netflix, causou certo espanto ao revelar, para que ainda não sabia, como as plataformas digitais controlam nossas relações e comportamentos nas redes sociais e, principalmente, nossas decisões de consumo.

O que o filme não aborda é como as redes sociais também reproduzem ou intensificam o racismo e o machismo tão presentes em nossa sociedade.

O perfil majoritário dos profissionais das grandes empresas de tecnologia que fornecem seus depoimentos no filme já aponta para a falta de diversidade na condução das principais plataformas digitais.

A campanha Busca por Igualdade do Desabafo Social cobrou respostas por diversidade dos principais bancos de imagens Imagem: Reprodução Internet

Alguns casos denunciados recentemente revelam o desafio colocado para as redes sociais que é impedir que a internet, com potencial para ser um espaço democrático e inclusivo, fortaleça preconceitos e segregações.

Na semana passada, a produtora de conteúdos digitais, Sá Ollebar, que mantem o perfil Preta Pariu sobre autocuidado e maternidade, realizou um experimento para entender porque suas produções estavam diminuindo o alcance de público no Instagram.

Ao postar os mesmos conteúdos temáticos, só que ilustrados por fotos de mulheres brancas, Sá percebeu um aumento de 6000% no alcance das publicações. Não se trata de mais curtidas ou comentários, mas de um número bem maior de pessoas atingidas pelos posts, o que é algo do controle da plataforma digital.

Racismo algorítimo

Seria impossível que nós recebêssemos todos os conteúdos publicados por aqueles que seguimos nas redes sociais. Daí, cabe às plataformas selecionar o que vemos. Isso é feito por meio dos algoritmos, que são sequencias de instruções ou regras aplicadas às máquinas.

A produtora de conteúdos digitais, Sá Ollebar, experimentou substituir suas fotos por de mulheres brancas e viu crescer o alcance dos seus posts Imagem: Roseane Moura / Amor Próprio Retratos

O que o experimento de Sá, repetido por outras produtoras de conteúdo ao longo desta semana, sugere é que a própria rede social (ou seus algoritmos) não privilegia as produções de pessoas negras.

É mais um exemplo do que pesquisadores em tecnologia tem chamado de "racismo algorítmico" ou "racismo tecnológico".

Diga-me o que o Google mostra e te direi de que mundo és

Para entender do que se trata, quem lê esse texto pode fazer um teste: colocar a expressão "família feliz" na busca por imagem do Google ou outro buscador de internet.

Tentem outras expressões como "mulher linda", "homem bonito", "criança linda", "bebês bonitos", ou simplesmente "pessoas". O resultado revela como a tecnologia já apreendeu os padrões estéticos priorizados pelos humanos em sociedades racistas como a brasileira.

Em 2017, a campanha "Busca Pela Igualdade", lançada pela organização Desabafo Social, de Monique Evelle, questionou a falta de diversidade nos principais bancos de imagens do mundo.

As imagens disponibilizadas nestes bancos são utilizadas por agências de publicidades e reproduzidas por produtores de conteúdos nas redes sociais, mantendo padrões que não expressam a diversidade da população.

Reconhecimento facial

Em 2013, a pesquisadora da Universidade da Califórnia, Safiya Umoja Noble revelou que a busca por "black girls" resultava em conteúdos pornográficos, machistas e sexistas, consequência da hiperssexualização das mulheres negras ensinada aos algoritmos.

Safiya lançou o livro Algoritmos da Opressão, demonstrando que tecnologias como essas de busca não são neutras e estão a serviço de interesses que muitas vezes perpetuam práticas discriminatórias.

Joy Buolamwini é cientista da computação no prestigiado MIT e denunciou falhas nas tecnologias de reconhecimento em pessoas negras Imagem: Tony Luong / The New York Times

Na mesma direção, a ativista digital Joy Buolamwini, pesquisadora do MIT, denunciou viés racista nos recursos de reconhecimento facial. Ela revelou como os robôs apresentam dificuldade para reconhecer pessoas negras.

Já há casos, inclusive no Brasil, de prisões equivocas geradas por erros em reconhecimento de suspeitos.

Carros autônomos

Mais recentemente, pesquisadores da George Institute of Technology descobriram que o sistema de programação dos carros autônomos treina os veículos para identificar melhor pedestres de pele clara, o que pode levar a mais chance de atropelar pessoas negras.

Ou seja, não se trata apenas de seleções estéticas ou busca por engajamentos nas redes. São decisões que podem resultar na retirada da liberdade ou da vida de alguém.

Todos esses casos foram mapeados e reunidos em uma Linha do Tempo do Racismo Algorítmico produzida e disponibilizada pelo doutorando da Universidade Federal do ABC (UFBAC), Tarcízio Silva.

Ele utiliza o conceito de microagressões raciais para demonstrar como essas violações são cotidianas, por vezes sutis, e presentes nos diferentes usos das tecnologias digitais.

Tarcízio é organizador da publicação "Comunidades, Algoritmos e Ativismos digitais: olhares afrodiaspóricos (LiteraRUA, 2020), entre outras obras sobre dados e inteligência artificial.

Diversidade agrega valor

As plataformas digitais têm dado respostas muito lentas a essas descobertas dos pesquisadores e geralmente se limitam a informar que "não era essa a intenção ao criar a tecnologia.

O mesmo dito no filme Dilema das Redes pelo criador do recurso Curtir ao se deparar com as consequências negativas da sua invenção.

O pesquisador Tarcízio Silva mantem atualizado um mapeamento de casos de racismo envolvendo inteligência artificial Imagem: Acervo Pessoal

Já sabemos que essas empresas de tecnologia são movidas pelo interesse no consumo. Mas também já sabemos que a diversidade agrega valor aos produtos e serviços e tem motivado as escolhas de consumidores conscientes.

Até as grandes empresas do capitalismo têm entendido que diversidade é bom para todos.

É preciso um compromisso de plataformas digitais e usuários das redes sociais para que a internet não repita as opressões e segregações que o mundo tenta corrigir em seu cotidiano offline.