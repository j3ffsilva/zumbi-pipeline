Recentemente, foi exposto no Twitter que seu algoritmo de fotos para gerar visualiza√ß√µes mostra pessoas brancas com mais frequ√™ncia que pessoas negras. O mesmo aconteceu no Instagram. Influenciadores negros notaram que a rede prioriza o engajamento de perfis brancos e limita o engajamento de perfis pretos. V√°rios usu√°rios fizeram o teste e conclu√≠ram que a intelig√™ncia artificial e os algoritmos das plataformas t√™m liga√ß√£o com o racismo.

Quando voc√™ publica uma imagem muito grande ou fora das propor√ß√µes no Twitter, por exemplo, a plataforma automaticamente escolhe um peda√ßo do retrato para exibir e prioriza os rostos humanos que forem identificados. Nos posts abaixo, √© poss√≠vel notar que o algoritmo projetado para otimizar a visualiza√ß√£o de imagens no feed da rede social sempre oculta pessoas negras, revelando os perigos √©ticos da intelig√™ncia artificial.

I wonder if Twitter does this to fictional characters too. Lenny Carl pic.twitter.com/fmJMWkkYEf ‚Äî Jordan Simonovski (@_jsimonovski) September 20, 2020

Trying a horrible experiment‚Ä¶ Which will the Twitter algorithm pick: Mitch McConnell or Barack Obama? pic.twitter.com/bR1GRyCkia ‚Äî Tony ‚ÄúAbolish (Pol)ICE‚Äù Arcieri ü¶Ä (@bascule) September 19, 2020

Estimulados pela pol√™mica do Twitter, influenciadores negros do Instagram tamb√©m resolveram fazer o teste. A S√° Ollebar, por exemplo, decidiu publicar fotos s√≥ de mulheres brancas em seu feed ap√≥s ver seus n√∫meros de seguidores e likes diminu√≠rem. Como resultado, ap√≥s as publica√ß√µes, seu engajamento teve um aumento de cerca de 6.000%!

A criadora de conte√∫do Luana Carvalho replicou o teste e teve resultados semelhantes. Muitos de seus seguidores declararam que n√£o eram impactados por seus conte√∫dos h√° semanas, mas que receberam de uma s√≥ vez as tr√™s publica√ß√µes que ela fez com mulheres brancas.

Continua ap√≥s a publicidade

Mas, afinal, o que √© algoritmo?

De uma forma simples, algoritmo √© uma sequ√™ncia de racioc√≠nios, opera√ß√µes ou instru√ß√µes usadas para alcan√ßar um determinado objetivo. √â como se fossem v√°rias receitas de pratos diferentes para voc√™ preparar um banquete completo. Ou seja, ele engloba todos os cen√°rios poss√≠veis para um usu√°rio da rede.

Um dos principais pontos levantados pela discuss√£o √© como √© poss√≠vel construir cen√°rios diversos para usu√°rios se quem est√° fazendo as programa√ß√µes s√£o majoritariamente homens brancos de classe m√©dia alta? Quando n√£o h√° diversidade de ra√ßa, g√™nero e classe social, fica muito dif√≠cil retratar cen√°rios poss√≠veis para pessoas em diferentes segmentos da sociedade. O que acaba acontecendo √© uma reprodu√ß√£o do poder que enxergamos na ‚Äúvida real‚Äù. Por isso, n√£o necessariamente o algoritmo em si √© racista, mas toda a sua constru√ß√£o ao redor √©.

Assim como o algoritmo, os recursos de intelig√™ncia artificial est√£o sendo cada vez mais utilizados por empresas e governos, sendo aplicados em sistemas de seguran√ßas e plataformas de m√≠dias sociais. A vis√£o computacional, que √© uma aplica√ß√£o da intelig√™ncia artificial, permite reconhecer automaticamente objetos, conceitos, caracter√≠sticas extra√≠das de imagens e at√© mesmo pessoas. Certas aplica√ß√µes, contudo, merecem aten√ß√£o redobrada, pois podem refor√ßar pr√°ticas que invisibilizam pessoas negras, como foram os casos denunciados pelos usu√°rios do Twitter e do Instagram.

Chegamos ent√£o a outra quest√£o: a falta de diversidade nos bancos de imagens. De onde ser√° que v√™m as fotos que servem como base para esses sistemas? Essa pergunta foi analisada pela cientista da computa√ß√£o Shreya Shankar e alguns de seus colaboradores, que conclu√≠ram que a maioria das imagens do ImageNet e Open Images, por exemplo, famosos bancos de fotos, vem dos Estados Unidos e da Gr√£ Bretanha. Outros pa√≠ses possuem fra√ß√µes muito pequenas de representa√ß√£o.

A intelig√™ncia artificial aprende com bancos de dados constru√≠dos por programadores e cientistas da computa√ß√£o. S√£o lugares em que a popula√ß√£o negra est√° pouco inserida. Dados de 2016 do Minist√©rio do Trabalho e Emprego (MTE) mostram a diferen√ßa racial no setor: brancos somam 92% na √°rea de engenharia de equipamento em computa√ß√£o e 88% no setor da aeron√°utica, enquanto pretos e pardos s√£o maioria apenas em trabalhos informais.

O que diz o Twitter?

O Twitter, por sua vez, fez alguns testes n√£o-cient√≠ficos e n√£o-oficiais para entender esse comportamento. O chefe do setor de design da rede social, Dantley Davis, conseguiu reverter um dos testes dos internautas ao esconder as m√£os do modelo negro e vesti-lo com o mesmo terno do modelo branco.

Here's another example of what I've experimented with. It's not a scientific test as it's an isolated example, but it points to some variables that we need to look into. Both men now have the same suits and I covered their hands. We're still investigating the NN. pic.twitter.com/06BhFgDkyA ‚Äî Dantley üî•‚úäüèæüíô (@dantley) September 20, 2020

A plataforma, por meio de sua conta, afirmou: ‚ÄúN√£o encontramos evid√™ncias de preconceito racial ou de g√™nero em nossos testes. Mas est√° evidente que temos mais an√°lises para fazer. Continuaremos a compartilhar o que aprendemos, quais a√ß√µes tomamos e abriremos o c√≥digo para que outros possam revisar e replicar.‚Äù

We tested for bias before shipping the model & didn't find evidence of racial or gender bias in our testing. But it‚Äôs clear that we‚Äôve got more analysis to do. We'll continue to share what we learn, what actions we take, & will open source it so others can review and replicate. ‚Äî Twitter Comms (@TwitterComms) September 20, 2020

A quest√£o ainda precisa ser analisada mais a fundo e √© importante que esses pontos continuem sendo expostos, principalmente porque essa discuss√£o n√£o √© nova. Apesar de a tecnologia ter avan√ßado bastante, s√£o necess√°rias muitas melhorias cont√≠nuas tamb√©m. Afinal, a estrat√©gia contra o racismo precisa envolver toda a sociedade.