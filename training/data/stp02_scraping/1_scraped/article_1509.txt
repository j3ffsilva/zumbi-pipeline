A pesquisadora do Google Timnit Gebru recebeu um email no inÃ­cio de dezembro, enquanto estava de fÃ©rias. â€œAceitamos sua demissÃ£o imediatamente, a partir de hojeâ€, escreveu-lhe uma vice-presidenta da empresa. O problema Ã© que Gebru nÃ£o havia pedido demissÃ£o, sÃ³ tinha dito que faria isso no futuro se nÃ£o fossem cumpridas certas condiÃ§Ãµes. A decisÃ£o tinha sido provocada aparentemente por uma mensagem interna no qual criticou a censura a um artigo acadÃªmico. Ela foi imediatamente ao Twitter para contar: â€œMeu acesso Ã  conta corporativa foi cortado. Fui demitida imediatamenteâ€. â€œEu me sinto mal por meus colegas, mas para mim Ã© melhor conhecer a besta do que fingirâ€, acrescentou em outro tuÃ­te.

I was fired by @JeffDean for my email to Brain women and Allies. My corp account has been cutoff. So I've been immediately fired :-) â€” Timnit Gebru (@timnitGebru) December 3, 2020

Desde aquele dia, e atÃ© sexta-feira passada, 2.351 funcionÃ¡rios do Google e 3.729 acadÃªmicos do mundo todo assinaram uma carta em apoio a Gebru. O presidente-executivo do Google, Sundar Pichai, enviou um email a todos os funcionÃ¡rios, no qual afirmou querer recuperar a confianÃ§a de seus trabalhadores, mas sem pedir desculpas. A comunidade global de engenheiros e pesquisadores dedicados Ã  inteligÃªncia artificial mantÃ©m desde entÃ£o um debate sobre os limites da pesquisa financiada por grandes companhias e o papel do Google como empresa, que jÃ¡ tirou todas as suas mÃ¡scaras apÃ³s abandonar seu ingÃªnuo slogan original, â€œnÃ£o seja mauâ€.

Gebru Ã© uma pesquisadora pioneira na Ã¡rea de Ã©tica em inteligÃªncia artificial (IA). Sua maior realizaÃ§Ã£o acadÃªmica foi um artigo de 2018 no qual, com outros coautores, descobriu que o reconhecimento facial se enganava apenas 1% das vezes ao detectar o gÃªnero de homens brancos, mas 35% no caso de mulheres negras. Depois de chegar de EtiÃ³pia com 16 anos, ela se formou em Engenharia ElÃ©trica na Universidade de Stanford e participou da criaÃ§Ã£o do primeiro iPad na Apple. Depois passou pela Microsoft. ApÃ³s seu doutorado em visÃ£o artificial com a cÃ©lebre professora Fei Fei Li, chegou ao Google no fim de 2018.

O tipo de demissÃ£o â€”por email, quando ela estava de fÃ©riasâ€” nÃ£o Ã© o habitual para uma figura desse nÃ­vel. â€œDemitir uma pessoa por email Ã© a segunda pior forma, atrÃ¡s apenas de fazer isso com um post-itâ€, escreveu o professor e engenheiro espanhol Ricardo Baeza Yates em resposta a Gebru. As especulaÃ§Ãµes sobre as verdadeiras causas da demissÃ£o dispararam. Estas sÃ£o as causas mais comentadas. Todas refletem, no mÃ­nimo, certa falta de sensibilidade, o que deixa o Google em mÃ¡ posiÃ§Ã£o por seu comportamento generoso ou delicado com assediadores e outros casos de destaque.

1) O correio eletrÃ´nico. O email da vice-presidenta mencionava uma mensagem de correio eletrÃ´nico que Gebru escreveu para uma lista interna de funcionÃ¡rios do Google. â€œAlguns aspectos do email que vocÃª enviou ontem Ã  noite para funcionÃ¡rios que nÃ£o sÃ£o da direÃ§Ã£o refletem um comportamento inconsistente com o que se espera de um executivo do Googleâ€. O que dizia aquela mensagem de Gebru? Ela nÃ£o pÃ´de recuperÃ¡-la porque jÃ¡ nÃ£o tinha acesso Ã  sua conta. Mas, em poucas horas, jÃ¡ estava na newsletter do jornalista Casey Newton. â€œDepois de todas as micro e macro agressÃµes e perseguiÃ§Ãµes que recebi apÃ³s postar minhas histÃ³rias aqui, eu tinha parado de escreverâ€, havia escrito Gebru.

I understand the concern over Timnitâ€™s resignation from Google. Sheâ€™s done a great deal to move the field forward with her research. I wanted to share the email I sent to Google Research and some thoughts on our research process.https://t.co/djUGdYwNMb â€” Jeff Dean (@ğŸ¡) (@JeffDean) December 4, 2020

Mas naquele dia a pesquisadora tinha algo mais a dizer. O texto inteiro Ã© um desabafo, uma queixa pÃºblica sobre como seus superiores a trataram em relaÃ§Ã£o a um artigo acadÃªmico do qual deveria se â€œretratarâ€. â€œUma semana antes de sair de fÃ©rias, vocÃª vÃª uma reuniÃ£o aparecer na sua agendaâ€ contou Gebru. â€œNinguÃ©m avisa sobre o quÃª. Nela, dizem que â€˜foi decididoâ€™ que vocÃª deve retificar o paper em uma semana. VocÃª nÃ£o Ã© digna de ter nenhuma conversa sobre isso, jÃ¡ que nÃ£o Ã© alguÃ©m cuja humanidade (sem falar da reconhecida expertise) seja aceita ou valorizada por esta empresaâ€.

Era uma mensagem sobre a suposta censura a um artigo acadÃªmico que Gebru e outras pesquisadoras, de dentro e fora do Google, tinham enviado a uma conferÃªncia. De repente, esse artigo nÃ£o parecia ter qualidade suficiente. Que informaÃ§Ã£o conteria esse artigo que tanto preocupava o Google?

2) O artigo acadÃªmico. NinguÃ©m publicou o artigo inteiro. Mas alguns jornalistas puderam lÃª-lo. NÃ£o hÃ¡ nada explosivo para o setor de IA Ã©tica. Fala do enorme gasto de energia que significa elaborar modelos de IA: precisam de muito poder de computaÃ§Ã£o. TambÃ©m se refere aos vieses criados por modelos que escrevem depois de treinar com trilhÃµes de palavras encontradas na Internet. â€œAs injustiÃ§as estruturais que existem na sociedade permeiam os dados. Ã‰ muito difÃ­cil encontrar dados nÃ£o tendenciosos, porque a sociedade Ã© tendenciosaâ€, explica Ariel Guersenzvaig, professor da Escola UniversitÃ¡ria de Desenho e Engenharia Elisava (Barcelona). Com a linguagem, isso Ã© evidente: se os modelos forem treinados com o que dizemos, repetirÃ£o nossos padrÃµes para sempre.

â€œO que afirma o artigo, pelo que se publicou atÃ© agora, nÃ£o vou dizer que seja conhecido, mas quem conhece a literatura acadÃªmica nÃ£o vai se surpreender com nadaâ€, diz Guersenzvaig.

3) â€œA mulher negra com raivaâ€. Se nem o email nem o artigo parecem explosivos, talvez tenham sido sÃ³ a desculpa? â€œO paper Ã© provavelmente uma desculpa para se livrar de uma pessoa que, para eles, estava sendo problemÃ¡ticaâ€, diz Mara Balestrini, doutora em CiÃªncias da ComputaÃ§Ã£o pelo University College of London.

A definiÃ§Ã£o de â€œmulher negra com raivaâ€ Ã© a caricatura que a prÃ³pria Gebru faz sobre o papel que os comunicados do Google parecem querer atribuir a ela: uma pessoa conflituosa que mereceu a demissÃ£o por ser problemÃ¡tica. â€œEles me pintam como essa mulher negra com raiva porque colocam vocÃª neste terrÃ­vel local de trabalho e, se vocÃª fala sobre isso, vocÃª se torna um problemaâ€, afirma Gebru na Ãºnica entrevista que deu atÃ© agora depois do conflito. Um dos verbos que Gebru mais tem usado Ã© to gaslight (que, neste sentido, pode ser traduzido como â€œmanipularâ€), originÃ¡rio de uma peÃ§a teatral do inÃ­cio do sÃ©culo XX, levada depois ao cinema, na qual um homem assedia psicologicamente sua mulher, fazendo-a acreditar que estÃ¡ ficando louca. Trata-se de abusar e, ainda por cima, culpar o outro. Foi isso que o Google fez com ela, segundo Gebru.

Esses sÃ£o os fatos, mas o rebuliÃ§o que o caso provocou significa que tocou pontos sensÃ­veis. Em princÃ­pio, Ã© apenas mais uma demissÃ£o em uma empresa com 130.000 funcionÃ¡rios. EntÃ£o, por que causou um escÃ¢ndalo assim?

1) â€œSe fizeram isso comigo...â€. O grande problema que Gebru vÃª em sua situaÃ§Ã£o Ã© o de todas as mulheres negras que estÃ£o em situaÃ§Ã£o mais precÃ¡ria que a dela. Gebru fundou em 2016 o grupo Negros na IA. â€œA maior histÃ³ria para mim Ã© que, se acontece isso comigo, o que estarÃ¡ acontecendo com outras pessoas?â€, diz Gebru agora.

O Google tem 1,6% mulheres negras entre todos os seus funcionÃ¡rios, e apenas 0,7% em cargos tÃ©cnicos e 1,1% em cargos executivos. Quase 50% dos cargos executivos sÃ£o para homens brancos. â€œVocÃª tem assediadores ganhando milhÃµes de dÃ³laresâ€, diz Gebru. â€œTem todas essas pessoas com comportamento muito tÃ³xico, e outras dizendo: â€˜Ã‰ que sÃ£o valiosas para a empresaâ€, â€œoh, Ã© que sÃ£o socialmente desajeitadasâ€, ou o que seja. E vocÃª tem uma mulher negra que tem de provar seu valor uma e outra vez. Cheguei a um ponto em que meus conhecimentos sÃ£o valorizados pela pessoas, mas nÃ£o dentro do Googleâ€, acrescenta.

This is what makes me sad. The message that was sent to so many people. https://t.co/YnYL85taTP â€” Timnit Gebru (@timnitGebru) December 10, 2020

2) â€œSe fizeram isso com ela...â€. E uma empresa que trata assim seus funcionÃ¡rios brilhantes, como tratarÃ¡ seus bilhÃµes de usuÃ¡rios? Ã‰ o que pergunta Anna Jobin, sociÃ³loga e pesquisadora da Universidade de Lausanne (SuÃ­Ã§a). â€œSe uma companhia como o Google nÃ£o consegue suportar o que Timnit Gebru tem para dizer, nÃ£o consegue ouvir e aprender para inovar melhor, o que serÃ¡ que acontece com todas as outras questÃµes Ã©ticas de seu negÃ³cio? Portanto, nÃ£o Ã© que os assuntos pessoais [como os hipotÃ©ticos problemas de Gebru no Google] nÃ£o importem, e sim que jÃ¡ nÃ£o sÃ£o apenas pessoais. SÃ£o importantes social, polÃ­tica e eticamenteâ€, acrescenta.

3) Quem permitirÃ¡ que pesquisemos? As grandes empresas de tecnologia sÃ£o talvez a maior fonte de financiamento para pesquisadores como Gebru. As universidades sÃ£o essenciais, mas tÃªm muito menos dinheiro. â€œA Intel financiou meu doutorado. A diferenÃ§a em relaÃ§Ã£o ao que um doutorando espanhol podia fazer era abismalâ€, assinala Balestrini. â€œHÃ¡ muito poucos empregadores dessa natureza. Para a IA Ã©tica, se vocÃª nÃ£o estÃ¡ na universidade, nÃ£o hÃ¡ trabalho. Chegar ao Google ou ao Facebook Ã© a possibilidade de ter acesso a grandes volumes de dados.â€

O tratamento dispensado a Gebru poderia ser um ponto de virada para a contrataÃ§Ã£o de engenheiros de IA. Se os mais sensÃ­veis veem que o departamento de Ã©tica Ã© desprezado, talvez olhem para alÃ©m do Google para trabalhar. Balestrini Ã© cÃ©tica: â€œNÃ£o quero ser pessimista, mas eles nÃ£o vÃ£o parar de ter grupos de pesquisadores por isso. Se essas coisas mudarem, serÃ¡ por haver mais alerta sobre os problemas tÃ©cnicos e, ao mesmo tempo, por surgirem mais oportunidades de trabalho para pesquisadores, como ocorrerÃ¡ agora com o programa Horizon Europeâ€, diz.

A polÃªmica gerada lembra que o Google jÃ¡ nÃ£o Ã© o eterno herÃ³i das buscas. Os problemas que ocorrem dentro de seus escritÃ³rios sÃ£o vistos sob uma luz diferente.